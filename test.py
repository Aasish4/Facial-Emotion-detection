# -*- coding: utf-8 -*-
"""Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VcvLlJp1ShaxZsGyykhc7E7t9vxMobEM

## STEP 1: FACE DETECTION
For face detection clone one of mine repository *https://github.com/Aasish4/Face-detection-using-MTCNN.git* 
It gives better accuracy as compared to haar cascade classifier for face detection.
"""

!git clone https://github.com/Aasish4/Face-detection-using-MTCNN.git

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/Face-detection-using-MTCNN

# import all the dependencies
from keras.preprocessing.image import img_to_array
from keras.models import load_model
from mtcnn.mtcnn import MTCNN
import matplotlib.pyplot as plt
import numpy as np
import cv2

# initilize the face detector
face_detector = MTCNN()

# load the emotion detector
emotion_detector = '/content/face exp reg/model/mini_xception57.hdf5' # path of your downloaded weight file

# load the model and describe the 'emotions'
emotion_classifier = load_model(emotion_detector, compile=False)
EMOTIONS = ["angry","disgust","scared", "happy", "sad", "surprised","neutral"]

# grab the image to start the detection on
frame = cv2.imread('/content/face exp reg/images/angry.jpeg')

# get the faces inside the images using detector
face = face_detector.detect_faces(frame)

# draw the bounding box with emotion classification
def draw_box(frame, faces_list):
  for face in faces_list:
    # get the face coordinates
    x, y, w, h = face['box']

    # extract the region of interest
    roi = frame[y:y+h, x:x+w]

    # resize the image as for the detector
    roi = cv2.resize(roi, (48,48))

    # convert into gray scale
    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    roi = roi.astype('float32') / 255.0   # normalize
    roi = img_to_array(roi)   # into array
    roi = np.expand_dims(roi, axis=0)  # reshape

    # predict for the image
    preds = emotion_classifier.predict(roi)[0]  
    emotion_prob = np.max(preds)  # max prob
    labels = EMOTIONS[preds.argmax()]

    # finally draw the bbox with classification of emotion
    cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0),2)
    cv2.putText(frame, labels, (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,255,0),2)
  plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
  plt.show()

# run the algorithm
draw_box(frame, face)

